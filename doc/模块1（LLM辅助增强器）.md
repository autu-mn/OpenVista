# 模块1：LLM辅助增强器（LLM-assisted Enhancer）完整构建思路

## 一、核心定位

LLM作为辅助工具，为时序数据添加语义信息，不改变原有数据结构。目标是提升可解释性，让数值数据具备语义描述。

## 二、数据准备

### 1. 时序数据来源
- OpenDigger指标：OpenRank、活跃度、Star数、Fork数等
- GitHub API指标：代码提交数、Issue/PR响应时间等
- 时间范围：从数据中提取完整月份时间轴

### 2. 文本数据准备（按月对齐）
- 爬取策略：每月只爬1个最热门的Issue、1个最热门的PR、1个最热门的Commit
- 热度计算：Issue/PR用评论数、点赞数、参与人数加权；Commit用评论数和点赞数
- 时间对齐：严格对齐到月份时间轴，缺失月份用空值填充
- 数据存储：保存标题、内容摘要、热度分数、创建时间等

## 三、增强处理流程

### 1. 单月数据增强
- 输入：该月的数值指标（OpenRank、Star数等）+ 文本数据（最热门的Issue/PR/Commit）
- LLM任务：生成该月的综合描述（100字以内）
- 输出：描述该月项目状态、关键指标变化和重要事件
- 处理逻辑：结合数值趋势与文本事件，生成自然语言描述

### 2. 趋势识别增强
- 输入：多个月的数值+文本数据（3-6个月窗口）
- LLM任务：识别趋势模式（上升/下降/波动/周期性），并关联文本事件
- 输出：趋势类型、变化幅度、关键转折点、对应的文本事件
- 处理逻辑：分析数值变化，识别关键事件，建立事件与指标变化的关联

### 3. 关键点增强
- 输入：峰值/谷值月份的数值指标 + 对应的文本数据
- LLM任务：解释关键点出现的原因，关联文本事件
- 输出：关键点解释、关联事件、影响分析
- 处理逻辑：分析峰值/谷值出现时的文本事件，解释因果关系

### 4. 语义特征提取
- 输入：完整时序数据 + 文本数据密度
- 计算：数值特征（增长率、稳定性、波动性）+ 文本特征（事件密度、活跃度）
- LLM任务：将数值特征转换为语义标签
- 输出：增长率（高/中/低）、稳定性（高/中/低）、文本活跃度、整体状态
- 处理逻辑：结合数值统计与文本事件密度，生成综合语义特征

## 四、数据结构设计

### 1. 输入数据结构
- 时序数据：按月份组织的指标值字典
- 文本数据：按月份组织的文本事件字典（每月最多3个：Issue/PR/Commit）

### 2. 增强数据结构
- 单月增强：数值指标 + 文本数据 + 增强描述 + 语义特征
- 趋势增强：趋势列表（每个趋势包含时间段、类型、描述、关键事件）
- 关键点增强：关键点列表（每个关键点包含日期、值、类型、解释）
- 整体总结：项目发展趋势的综合描述

### 3. 输出数据结构
- 按月组织：每个月份包含原始数据、文本数据、增强描述、语义特征
- 跨月分析：趋势列表、关键点列表、整体总结
- 时间轴：完整的月份列表，用于前端展示

## 五、LLM调用策略

### 1. Prompt设计原则
- 结构化输入：提供清晰的数值指标和文本事件
- 明确任务：明确要求生成描述、识别趋势、解释关键点
- 格式控制：指定输出格式（JSON或自然语言）
- 长度控制：限制输出长度，避免过长

### 2. 调用优化
- 缓存机制：相同输入缓存结果，避免重复调用
- 批量处理：一次处理多个月份，减少调用次数
- 降级策略：LLM失败时使用规则生成默认描述
- 错误处理：重试机制、超时处理、异常捕获

### 3. Token消耗控制
- 文本截断：文本内容限制在500字符以内
- 选择性增强：只对关键月份进行详细增强
- 缓存复用：相同数据复用缓存结果

## 六、与原有系统集成

### 1. 数据流集成
- 数据爬取阶段：在爬取时序数据后，同步爬取文本数据
- 数据处理阶段：在生成时序数据后，进行增强处理
- 数据存储阶段：增强数据单独存储或合并到原数据中

### 2. API接口集成
- 新增接口：获取增强数据的API接口
- 兼容性：不影响原有接口，增强数据作为可选字段
- 前端展示：前端可选择是否展示增强信息

### 3. 性能考虑
- 异步处理：增强处理可以异步进行，不阻塞主流程
- 按需加载：前端按需加载增强数据，减少初始加载时间
- 缓存策略：增强结果缓存，避免重复计算

## 七、应用场景

### 1. 前端展示增强
- 图表旁显示指标说明和趋势描述
- 关键时间点显示关联事件
- 整体趋势总结卡片

### 2. 报告生成
- 自动生成月度/季度/年度分析报告
- 包含数值趋势和文本事件分析
- 提供可解释的洞察

### 3. 用户理解提升
- 降低理解门槛：用自然语言解释数据
- 关联事件：帮助理解指标变化原因
- 趋势预测：基于历史趋势和事件预测未来

## 八、优势与特点

### 1. 技术优势
- 无需训练模型：直接使用LLM，无需训练
- 不破坏原有结构：增强数据作为附加信息
- 可解释性强：提供语义描述和事件关联
- 易于扩展：可随时添加新的增强维度

### 2. 业务优势
- 提升用户体验：更直观的数据理解
- 增强分析能力：结合文本事件的分析
- 降低使用门槛：非技术人员也能理解数据
- 提高决策质量：提供更全面的洞察

### 3. 成本优势
- 每月只爬1个Issue/PR/Commit，API调用少
- LLM调用可缓存，减少重复调用
- 选择性增强，只处理关键数据

## 九、实施步骤

### 1. 第一阶段：数据准备
- 修改爬虫：增加按月爬取最热门文本数据的功能
- 数据对齐：实现文本数据与时间轴的对齐逻辑
- 数据存储：设计增强数据的存储结构

### 2. 第二阶段：增强器实现
- 实现单月增强：生成单月综合描述
- 实现趋势识别：识别趋势并关联事件
- 实现关键点增强：解释关键点出现原因
- 实现语义特征提取：生成语义标签

### 3. 第三阶段：系统集成
- API接口：提供获取增强数据的接口
- 前端展示：在图表中展示增强信息
- 缓存优化：实现缓存机制，提升性能

### 4. 第四阶段：优化完善
- Prompt优化：根据效果调整Prompt
- 性能优化：优化LLM调用和缓存策略
- 用户体验：优化前端展示效果

## 十、预期效果

### 1. 数据层面
- 每个月份都有对应的文本事件数据
- 每个指标都有语义描述和趋势分析
- 关键点都有事件关联和解释

### 2. 用户层面
- 用户能更直观地理解数据含义
- 用户能了解指标变化的原因
- 用户能获得更全面的分析洞察

### 3. 系统层面
- 系统具备更强的可解释性
- 系统提供更丰富的分析维度
- 系统具备更好的用户体验

---

这就是模式1的完整构建思路：通过LLM为时序数据添加语义信息，结合文本事件，提升数据的可解释性和分析价值。

