# 模块2（LLM为中心的预测器）改进说明

## 改进前的问题

1. **缺乏文本时序融合**：
   - 原版只使用数值时序数据
   - 没有利用Issue/PR/Commit等文本事件信息
   - 预测缺乏对项目实际活动的理解

2. **置信度缺乏科学依据**：
   - 原版置信度由LLM直接输出，主观性强
   - 没有基于数据质量的量化评估
   - 无法解释置信度的来源

## 改进内容

### 1. 文本时序数据融合

#### 1.1 关键事件提取
```python
def _extract_key_events(self, historical_data, text_timeseries, trend_analysis):
    """
    从文本时序数据中提取关键事件
    
    策略：
    1. 识别指标变化超过15%的月份
    2. 提取该月份的热门Issue/PR/Commit
    3. 关联事件与指标变化
    """
```

**示例输出**：
```json
{
  "key_events": [
    {
      "month": "2024-03",
      "change_rate": 25.3,
      "direction": "上升",
      "issue": "Add new feature: Real-time collaboration",
      "pr": "Implement WebSocket support",
      "commit": "Major refactoring of core engine"
    }
  ]
}
```

#### 1.2 增强的Prompt设计

**原版Prompt**：
- 只有历史数值
- 简单的趋势描述

**改进后Prompt**：
```
【关键事件与指标变化】

2024-03 (上升25.3%):
  - Issue: Add new feature: Real-time collaboration
  - PR: Implement WebSocket support
  - Commit: Major refactoring of core engine

【预测策略】
1. 趋势延续：分析历史趋势是否会延续
2. 事件影响：关键事件对指标的影响是短期还是长期
3. 季节性模式：是否存在周期性波动
4. 回归均值：极端值后通常会回归到正常水平
5. 波动性考虑：历史波动性高的指标，预测应更保守
```

### 2. 科学的置信度计算

#### 2.1 置信度因子

置信度由4个因子综合计算：

```python
def _calculate_confidence_factors(self, historical_data, trend_analysis, text_timeseries):
    """
    计算科学的置信度因子
    
    因子：
    1. data_completeness: 数据完整性（缺失值比例）
    2. trend_stability: 趋势稳定性（基于变异系数）
    3. data_volume: 数据量充足性（样本数量）
    4. text_alignment: 文本数据对齐度（如果有文本数据）
    """
```

#### 2.2 各因子计算方法

**1. 数据完整性 (data_completeness)**
```python
completeness = 有效数据点数 / 总数据点数
```
- 范围：0-1
- 越接近1表示数据越完整

**2. 趋势稳定性 (trend_stability)**
```python
# 基于变异系数 (CV = 标准差 / 平均值)
if CV < 0.1:  stability = 0.95
elif CV < 0.2:  stability = 0.85
elif CV < 0.3:  stability = 0.70
elif CV < 0.5:  stability = 0.50
else:  stability = 0.30
```
- CV越小，趋势越稳定，预测越可靠

**3. 数据量充足性 (data_volume)**
```python
if data_count >= 24:  volume_score = 0.95  # 2年以上数据
elif data_count >= 12:  volume_score = 0.80  # 1年数据
elif data_count >= 6:  volume_score = 0.60  # 半年数据
else:  volume_score = 0.40  # 数据不足
```

**4. 文本对齐度 (text_alignment)**
```python
alignment = 有文本数据的月份数 / 总月份数
```
- 有文本数据的月份越多，预测越准确

#### 2.3 综合置信度

```python
confidence = (data_completeness + trend_stability + data_volume + text_alignment) / 4
```

### 3. 数据质量分析

新增数据质量分析模块：

```python
def _analyze_data_quality(self, data):
    """
    分析数据质量
    
    指标：
    1. completeness: 完整性
    2. outlier_count: 异常值数量（使用IQR方法检测）
    3. missing_count: 缺失值数量
    4. total_points: 总数据点数
    """
```

**异常值检测（IQR方法）**：
```python
Q1 = 第25百分位数
Q3 = 第75百分位数
IQR = Q3 - Q1
异常值 = 值 < Q1 - 1.5*IQR 或 值 > Q3 + 1.5*IQR
```

### 4. API接口更新

#### 4.1 新增参数

```python
POST /api/predict/<repo_key>
{
    "metric_name": "OpenRank",
    "forecast_months": 6,
    "include_reasoning": true,
    "include_text_data": true,  # 新增：是否包含文本数据
    "repo_context": "项目描述..."  # 新增：仓库上下文
}
```

#### 4.2 增强的响应

```json
{
    "forecast": {...},
    "confidence": 0.78,
    "confidence_factors": {
        "data_completeness": 0.95,
        "trend_stability": 0.80,
        "data_volume": 0.85,
        "text_alignment": 0.52
    },
    "reasoning": "基于历史趋势和关键事件分析...",
    "key_events": [...],
    "data_quality": {
        "completeness": 0.95,
        "outlier_count": 2,
        "missing_count": 3,
        "total_points": 60
    }
}
```

## 使用示例

### 基础预测（仅数值）

```python
from LLM2TSA.predictor import LLMTimeSeriesPredictor

predictor = LLMTimeSeriesPredictor()

result = predictor.predict(
    metric_name="OpenRank",
    historical_data={"2024-01": 10.5, "2024-02": 11.2, ...},
    forecast_months=6
)

print(f"置信度: {result['confidence']:.2%}")
print(f"置信度因子: {result['confidence_factors']}")
```

### 增强预测（融合文本）

```python
# 准备文本时序数据
text_timeseries = {
    "2024-01": {
        "hottest_issue": {"title": "...", "comments": 50},
        "hottest_pr": {"title": "...", "reactions": 30},
        "hottest_commit": {"message": "..."}
    },
    ...
}

result = predictor.predict(
    metric_name="OpenRank",
    historical_data=historical_data,
    forecast_months=6,
    text_timeseries=text_timeseries,
    repo_context="这是一个流行的Web框架..."
)

# 查看关键事件
for event in result['key_events']:
    print(f"{event['month']}: {event['direction']} {event['change_rate']}%")
    if event.get('issue'):
        print(f"  Issue: {event['issue']}")
```

## 改进效果

### 1. 预测质量提升

- **原版**：简单线性外推，容易过拟合
- **改进后**：结合事件影响，预测更合理

### 2. 可解释性增强

- **原版**：置信度黑盒，无法解释
- **改进后**：
  - 4个可量化的置信度因子
  - 明确的计算公式
  - 数据质量报告

### 3. 适用场景扩展

- **原版**：仅适用于平稳时序
- **改进后**：
  - 可处理有重大事件影响的时序
  - 可识别异常值和数据质量问题
  - 可根据波动性调整预测策略

## 后续优化方向

1. **多模型集成**：
   - 结合传统时序模型（ARIMA、Prophet）
   - LLM预测 + 统计模型预测的加权平均

2. **自适应置信度**：
   - 根据历史预测准确率动态调整
   - 建立预测误差反馈机制

3. **更丰富的文本特征**：
   - 情感分析（Issue/PR的情绪倾向）
   - 主题建模（项目发展方向）
   - 贡献者网络分析

4. **预测区间**：
   - 不仅给出点预测，还给出预测区间
   - 基于置信度计算上下界

## 技术细节

### 变异系数（CV）

变异系数是标准差与平均值的比值，用于衡量数据的相对波动性：

```
CV = σ / μ

其中：
σ = 标准差
μ = 平均值
```

**优点**：
- 无量纲，可比较不同量级的指标
- 反映相对波动性，而非绝对波动性

**解释**：
- CV < 0.1：波动很小，趋势稳定
- 0.1 ≤ CV < 0.3：波动适中
- CV ≥ 0.3：波动较大，预测不确定性高

### IQR异常值检测

四分位距（IQR）方法是一种稳健的异常值检测方法：

```
Q1 = 第25百分位数
Q3 = 第75百分位数
IQR = Q3 - Q1

异常值定义：
- 下界：Q1 - 1.5 * IQR
- 上界：Q3 + 1.5 * IQR
```

**优点**：
- 不受极端值影响
- 适用于非正态分布
- 广泛应用于数据分析

## 总结

改进后的模块2实现了：

1. ✅ **文本时序融合**：关键事件提取和影响分析
2. ✅ **科学置信度**：4个可量化因子，透明计算
3. ✅ **数据质量分析**：完整性、异常值检测
4. ✅ **增强Prompt**：结合趋势、事件、策略的综合预测
5. ✅ **可解释性**：详细的置信度因子和数据质量报告

这些改进使预测更加可靠、可解释，符合科学研究的要求。

