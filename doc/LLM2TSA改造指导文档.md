# DataPulse LLM2TSA æ”¹é€ æŒ‡å¯¼æ–‡æ¡£

## ğŸ“‹ ç›®å½•

1. [æ¦‚è¿°](#æ¦‚è¿°)
2. [æ¶æ„è®¾è®¡](#æ¶æ„è®¾è®¡)
3. [ä¸‰ç§æ¨¡å¼å®ç°æ–¹æ¡ˆ](#ä¸‰ç§æ¨¡å¼å®ç°æ–¹æ¡ˆ)
4. [é¡¹ç›®ç»“æ„æ”¹é€ ](#é¡¹ç›®ç»“æ„æ”¹é€ )
5. [æ•°æ®æµè®¾è®¡](#æ•°æ®æµè®¾è®¡)
6. [APIæ¥å£è®¾è®¡](#apiæ¥å£è®¾è®¡)
7. [å®ç°æ­¥éª¤](#å®ç°æ­¥éª¤)
8. [æŠ€æœ¯æ ˆä¸ä¾èµ–](#æŠ€æœ¯æ ˆä¸ä¾èµ–)

---

## æ¦‚è¿°

åŸºäº **LLM2TSAï¼ˆLarge Language Models for Time Series Analysisï¼‰** çš„ä¸‰ç§æ¨¡å¼ï¼Œå°† DataPulse ä»ä¼ ç»Ÿçš„æ•°æ®å±•ç¤ºå¹³å°å‡çº§ä¸º**æ™ºèƒ½æ—¶åºåˆ†æå¹³å°**ï¼Œèåˆ LLM çš„èƒ½åŠ›æ¥å¢å¼ºæ—¶åºæ•°æ®çš„ç†è§£ã€é¢„æµ‹å’Œåˆ†æèƒ½åŠ›ã€‚

### æ ¸å¿ƒç›®æ ‡

- **æ•°æ®å¢å¼º**ï¼šä¸ºæ—¶åºæ•°æ®æ·»åŠ è¯­ä¹‰æè¿°ï¼Œæå‡å¯è§£é‡Šæ€§
- **æ™ºèƒ½é¢„æµ‹**ï¼šä½¿ç”¨ LLM è¿›è¡Œæ—¶åºé¢„æµ‹ï¼Œæ— éœ€ä¼ ç»Ÿæ¨¡å‹è®­ç»ƒ
- **çŸ¥è¯†èåˆ**ï¼šç»“åˆé¢†åŸŸçŸ¥è¯†ï¼Œæä¾›æ›´ä¸“ä¸šçš„åˆ†ææ´å¯Ÿ

---

## æ¶æ„è®¾è®¡

### æ•´ä½“æ¶æ„å›¾

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        å‰ç«¯å±‚ (Frontend)                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚æ—¶åºå¯è§†åŒ–â”‚  â”‚è¶‹åŠ¿åˆ†æ  â”‚  â”‚æ™ºèƒ½é¢„æµ‹  â”‚  â”‚æ™ºèƒ½é—®ç­”  â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†• HTTP/SSE
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      APIå±‚ (Flask Backend)                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚æ•°æ®æœåŠ¡  â”‚  â”‚å¢å¼ºæœåŠ¡  â”‚  â”‚é¢„æµ‹æœåŠ¡  â”‚  â”‚æ™ºèƒ½ä½“æœåŠ¡â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†•
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    LLM2TSAæ ¸å¿ƒå±‚ (LLM Layer)                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  æ¨¡å¼1: LLMè¾…åŠ©å¢å¼ºå™¨ (LLM-assisted Enhancer)        â”‚  â”‚
â”‚  â”‚  - æ—¶åºæ•°æ®æ–‡æœ¬åŒ–æè¿°                                 â”‚  â”‚
â”‚  â”‚  - è¶‹åŠ¿æ€»ç»“ç”Ÿæˆ                                       â”‚  â”‚
â”‚  â”‚  - è¯­ä¹‰ç‰¹å¾æå–                                       â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  æ¨¡å¼2: LLMä¸ºä¸­å¿ƒçš„é¢„æµ‹å™¨ (LLM-centered Predictor)   â”‚  â”‚
â”‚  â”‚  - æ—¶åºæ•°æ®æ ¼å¼åŒ–ï¼ˆæ–‡æœ¬/åºåˆ—ï¼‰                        â”‚  â”‚
â”‚  â”‚  - Promptå·¥ç¨‹                                         â”‚  â”‚
â”‚  â”‚  - é¢„æµ‹ç»“æœè§£æ                                       â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  æ¨¡å¼3: LLMèµ‹èƒ½çš„æ™ºèƒ½ä½“ (LLM-empowered Agent)        â”‚  â”‚
â”‚  â”‚  - é¢†åŸŸçŸ¥è¯†åº“æ•´åˆ                                     â”‚  â”‚
â”‚  â”‚  - å¤šæ¨¡æ€æ•°æ®å¤„ç†                                     â”‚  â”‚
â”‚  â”‚  - å¤æ‚ä»»åŠ¡ç¼–æ’                                       â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†•
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      æ•°æ®å±‚ (Data Layer)                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚æ—¶åºæ•°æ®  â”‚  â”‚æ–‡æœ¬æ•°æ®  â”‚  â”‚çŸ¥è¯†åº“    â”‚  â”‚å…ƒæ•°æ®    â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ä¸‰ç§æ¨¡å¼å®ç°æ–¹æ¡ˆ

### æ¨¡å¼1: LLMè¾…åŠ©å¢å¼ºå™¨ (LLM-assisted Enhancer)

**æ ¸å¿ƒæ€æƒ³**ï¼šLLM ä½œä¸ºè¾…åŠ©å·¥å…·ï¼Œä¸ºæ—¶åºæ•°æ®æ·»åŠ è¯­ä¹‰ä¿¡æ¯ï¼Œä¸æ”¹å˜åŸæœ‰æ•°æ®ç»“æ„ã€‚

#### 1.1 æ•°æ®å¢å¼ºå±‚

**åŠŸèƒ½**ï¼š
- ä¸ºæ¯ä¸ªæ—¶åºæŒ‡æ ‡ç”Ÿæˆè‡ªç„¶è¯­è¨€æè¿°
- è¯†åˆ«è¶‹åŠ¿æ¨¡å¼ï¼ˆä¸Šå‡ã€ä¸‹é™ã€æ³¢åŠ¨ã€å‘¨æœŸæ€§ï¼‰
- ç”Ÿæˆå…³é”®æ—¶é—´ç‚¹çš„è§£é‡Šæ€§æ–‡æœ¬

**å®ç°ç¤ºä¾‹**ï¼š

```python
# backend/LLM2TSA/enhancer.py

class TimeSeriesEnhancer:
    """æ—¶åºæ•°æ®å¢å¼ºå™¨"""
    
    def enhance_metric(self, metric_name: str, time_series: Dict[str, float]) -> Dict:
        """
        ä¸ºå•ä¸ªæŒ‡æ ‡ç”Ÿæˆå¢å¼ºä¿¡æ¯
        
        è¾“å…¥ï¼š
        - metric_name: "OpenRank"
        - time_series: {"2020-08": 4.76, "2020-09": 4.93, ...}
        
        è¾“å‡ºï¼š
        {
            "description": "OpenRankæŒ‡æ ‡åæ˜ äº†é¡¹ç›®çš„å¼€æºå½±å“åŠ›...",
            "trends": [
                {"period": "2020-08 to 2021-02", "type": "ä¸Šå‡", "description": "..."},
                ...
            ],
            "key_points": [
                {"date": "2020-12", "value": 12.65, "description": "è¾¾åˆ°å³°å€¼..."},
                ...
            ],
            "semantic_features": {
                "growth_rate": "ä¸­ç­‰",
                "stability": "è¾ƒé«˜",
                "seasonality": "æ— æ˜æ˜¾å­£èŠ‚æ€§"
            }
        }
        """
        # 1. ç”ŸæˆæŒ‡æ ‡æè¿°
        description_prompt = f"""
        è¯·ä¸ºä»¥ä¸‹æ—¶åºæŒ‡æ ‡ç”Ÿæˆç®€æ´çš„æè¿°ï¼ˆ100å­—ä»¥å†…ï¼‰ï¼š
        æŒ‡æ ‡åç§°ï¼š{metric_name}
        æ•°æ®èŒƒå›´ï¼š{len(time_series)}ä¸ªæœˆ
        æœ€æ–°å€¼ï¼š{list(time_series.values())[-1]}
        """
        description = self.llm_client.generate(description_prompt)
        
        # 2. è¯†åˆ«è¶‹åŠ¿
        trends = self._detect_trends(time_series)
        
        # 3. æå–å…³é”®ç‚¹
        key_points = self._extract_key_points(time_series)
        
        # 4. ç”Ÿæˆè¯­ä¹‰ç‰¹å¾
        semantic_features = self._extract_semantic_features(time_series)
        
        return {
            "description": description,
            "trends": trends,
            "key_points": key_points,
            "semantic_features": semantic_features
        }
    
    def generate_summary(self, all_metrics: Dict[str, Dict]) -> str:
        """ç”Ÿæˆæ•´ä½“è¶‹åŠ¿æ€»ç»“"""
        summary_prompt = f"""
        åŸºäºä»¥ä¸‹æ—¶åºæŒ‡æ ‡æ•°æ®ï¼Œç”Ÿæˆä¸€ä»½é¡¹ç›®å‘å±•è¶‹åŠ¿æ€»ç»“ï¼ˆ300å­—ä»¥å†…ï¼‰ï¼š
        {json.dumps(all_metrics, ensure_ascii=False, indent=2)}
        """
        return self.llm_client.generate(summary_prompt)
```

#### 1.2 æ¨¡å‹å¢å¼ºå±‚ï¼ˆå¯é€‰ï¼Œæœªæ¥æ‰©å±•ï¼‰

**åŠŸèƒ½**ï¼šé€šè¿‡åŒå¡”æ¨¡å‹ç»“æ„ï¼Œå°† LLM å­¦åˆ°çš„é€šç”¨çŸ¥è¯†è¿ç§»åˆ°æ—¶åºæ¨¡å‹ä¸­ã€‚

**å®ç°æ€è·¯**ï¼š
- æ–‡æœ¬å¡”ï¼šLLM ç¼–ç å™¨ï¼ˆBERT/LLM Embeddingï¼‰
- æ—¶åºå¡”ï¼šæ—¶åºæ¨¡å‹ç¼–ç å™¨ï¼ˆLSTM/Transformerï¼‰
- èåˆå±‚ï¼šæ³¨æ„åŠ›æœºåˆ¶èåˆä¸¤ç§ç‰¹å¾

**å½“å‰é˜¶æ®µ**ï¼šå…ˆå®ç°æ•°æ®å¢å¼ºå±‚ï¼Œæ¨¡å‹å¢å¼ºå±‚ä½œä¸ºæœªæ¥æ‰©å±•ã€‚

---

### æ¨¡å¼2: LLMä¸ºä¸­å¿ƒçš„é¢„æµ‹å™¨ (LLM-centered Predictor)

**æ ¸å¿ƒæ€æƒ³**ï¼šä»¥ LLM ä¸ºæ ¸å¿ƒè¿›è¡Œæ—¶åºé¢„æµ‹ï¼Œæ— éœ€è®­ç»ƒä¼ ç»Ÿæ—¶åºæ¨¡å‹ã€‚

#### 2.1 ä¸è°ƒå‚è·¯å¾„ï¼ˆä¼˜å…ˆå®ç°ï¼‰

**ç‰¹ç‚¹**ï¼šæ— éœ€ä¿®æ”¹ LLM å‚æ•°ï¼Œä»…é€šè¿‡ Prompt å·¥ç¨‹å®ç°é¢„æµ‹ã€‚

**å®ç°æ­¥éª¤**ï¼š

1. **æ—¶åºæ•°æ®æ ¼å¼åŒ–**
   - å°†æ•°å€¼åºåˆ—è½¬æ¢ä¸ºæ–‡æœ¬æè¿°
   - æˆ–è½¬æ¢ä¸º LLM å¯ç†è§£çš„åºåˆ—æ ¼å¼

2. **Prompt è®¾è®¡**
   - æä¾›å†å²æ•°æ®ä¸Šä¸‹æ–‡
   - æ˜ç¡®é¢„æµ‹ä»»åŠ¡å’Œè¾“å‡ºæ ¼å¼
   - åŠ å…¥é¢†åŸŸçŸ¥è¯†æç¤º

3. **ç»“æœè§£æ**
   - è§£æ LLM è¾“å‡ºçš„é¢„æµ‹å€¼
   - å¤„ç†ä¸ç¡®å®šæ€§è¡¨è¾¾

**å®ç°ç¤ºä¾‹**ï¼š

```python
# backend/LLM2TSA/predictor.py

class LLMTimeSeriesPredictor:
    """LLMæ—¶åºé¢„æµ‹å™¨"""
    
    def predict(self, metric_name: str, historical_data: Dict[str, float], 
                forecast_months: int = 6) -> Dict:
        """
        é¢„æµ‹æœªæ¥æ—¶åºå€¼
        
        è¾“å…¥ï¼š
        - metric_name: "OpenRank"
        - historical_data: {"2020-08": 4.76, ..., "2025-11": 4.58}
        - forecast_months: 6
        
        è¾“å‡ºï¼š
        {
            "forecast": {
                "2025-12": 4.8,
                "2026-01": 5.1,
                ...
            },
            "confidence": 0.75,
            "reasoning": "åŸºäºå†å²è¶‹åŠ¿åˆ†æ..."
        }
        """
        # 1. æ ¼å¼åŒ–å†å²æ•°æ®
        formatted_data = self._format_timeseries(historical_data)
        
        # 2. æ„å»ºé¢„æµ‹ Prompt
        prompt = f"""
ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ—¶åºæ•°æ®åˆ†æä¸“å®¶ã€‚è¯·åŸºäºä»¥ä¸‹å†å²æ•°æ®é¢„æµ‹æœªæ¥{forecast_months}ä¸ªæœˆçš„å€¼ã€‚

æŒ‡æ ‡åç§°ï¼š{metric_name}
å†å²æ•°æ®ï¼ˆæœ€è¿‘24ä¸ªæœˆï¼‰ï¼š
{formatted_data}

è¯·æŒ‰ç…§ä»¥ä¸‹æ ¼å¼è¾“å‡ºé¢„æµ‹ç»“æœï¼š
```json
{{
    "forecast": {{
        "2025-12": <é¢„æµ‹å€¼>,
        "2026-01": <é¢„æµ‹å€¼>,
        ...
    }},
    "confidence": <ç½®ä¿¡åº¦ 0-1>,
    "reasoning": "<é¢„æµ‹ç†ç”±>"
}}
```

è¦æ±‚ï¼š
1. é¢„æµ‹å€¼åº”åŸºäºå†å²è¶‹åŠ¿å’Œæ¨¡å¼
2. è€ƒè™‘å¯èƒ½çš„å­£èŠ‚æ€§å˜åŒ–
3. ç½®ä¿¡åº¦åæ˜ é¢„æµ‹çš„å¯é æ€§
4. æä¾›ç®€è¦çš„é¢„æµ‹ç†ç”±
"""
        
        # 3. è°ƒç”¨ LLM
        response = self.llm_client.generate(prompt)
        
        # 4. è§£æç»“æœ
        result = self._parse_prediction(response)
        
        return result
    
    def _format_timeseries(self, data: Dict[str, float]) -> str:
        """å°†æ—¶åºæ•°æ®æ ¼å¼åŒ–ä¸ºæ–‡æœ¬"""
        # æ–¹å¼1ï¼šè¡¨æ ¼æ ¼å¼
        lines = ["æ—¶é—´\tå€¼"]
        for date, value in list(data.items())[-24:]:  # æœ€è¿‘24ä¸ªæœˆ
            lines.append(f"{date}\t{value:.2f}")
        return "\n".join(lines)
        
        # æ–¹å¼2ï¼šè‡ªç„¶è¯­è¨€æè¿°ï¼ˆå¯é€‰ï¼‰
        # "ä»2020å¹´8æœˆçš„4.76å¼€å§‹ï¼Œé€æ¸ä¸Šå‡è‡³2020å¹´12æœˆçš„12.65..."
```

#### 2.2 è°ƒå‚è·¯å¾„ï¼ˆæœªæ¥æ‰©å±•ï¼‰

**ç‰¹ç‚¹**ï¼šé’ˆå¯¹æ—¶åºä»»åŠ¡å¾®è°ƒ LLMï¼Œæˆ–æ·»åŠ ä¸“å±ä»»åŠ¡å±‚ã€‚

**å®ç°æ€è·¯**ï¼š
- ä½¿ç”¨ LoRA/QLoRA å¾®è°ƒ LLM
- æ·»åŠ æ—¶åºç‰¹å¾ç¼–ç å±‚
- å¤šä»»åŠ¡å­¦ä¹ ï¼ˆé¢„æµ‹ + åˆ†ç±» + å¼‚å¸¸æ£€æµ‹ï¼‰

**å½“å‰é˜¶æ®µ**ï¼šå…ˆå®ç°ä¸è°ƒå‚è·¯å¾„ï¼ŒéªŒè¯æ•ˆæœåå†è€ƒè™‘è°ƒå‚ã€‚

---

### æ¨¡å¼3: LLMèµ‹èƒ½çš„æ™ºèƒ½ä½“ (LLM-empowered Agent)

**æ ¸å¿ƒæ€æƒ³**ï¼šLLM ä½œä¸ºæ™ºèƒ½ä½“ï¼Œç»“åˆå¤–éƒ¨çŸ¥è¯†å¤„ç†å¤æ‚æ—¶åºåˆ†æä»»åŠ¡ã€‚

#### 3.1 é¢†åŸŸçŸ¥è¯†æ•´åˆ

**åŠŸèƒ½**ï¼š
- æ•´åˆå¼€æºé¡¹ç›®ç”Ÿæ€çŸ¥è¯†
- å†å²ç»éªŒåº“ï¼ˆç±»ä¼¼é¡¹ç›®çš„æ¨¡å¼ï¼‰
- è¡Œä¸šæ ‡å‡†å’Œæœ€ä½³å®è·µ

**å®ç°ç¤ºä¾‹**ï¼š

```python
# backend/LLM2TSA/agent.py

class TimeSeriesAgent:
    """æ—¶åºåˆ†ææ™ºèƒ½ä½“"""
    
    def __init__(self):
        self.knowledge_base = KnowledgeBase()  # é¢†åŸŸçŸ¥è¯†åº“
        self.llm_client = DeepSeekClient()
    
    def analyze_repository(self, repo_key: str, 
                          timeseries_data: Dict,
                          text_data: List[Dict]) -> Dict:
        """
        ç»¼åˆåˆ†æä»“åº“çš„æ—¶åºæ•°æ®
        
        è¾“å‡ºï¼š
        {
            "overall_assessment": "é¡¹ç›®å¤„äºå¿«é€Ÿå¢é•¿æœŸ...",
            "key_insights": [
                "OpenRankåœ¨è¿‡å»6ä¸ªæœˆä¸Šå‡äº†30%ï¼Œè¡¨æ˜å½±å“åŠ›æå‡",
                "Issueå“åº”æ—¶é—´ç¼©çŸ­ï¼Œç¤¾åŒºæ´»è·ƒåº¦æé«˜",
                ...
            ],
            "recommendations": [
                "å»ºè®®åŠ å¼ºæ–‡æ¡£ç»´æŠ¤ï¼Œæå‡æ–°ç”¨æˆ·ä¸Šæ‰‹ä½“éªŒ",
                ...
            ],
            "comparison": {
                "similar_repos": [...],
                "industry_benchmark": {...}
            }
        }
        """
        # 1. åŠ è½½é¢†åŸŸçŸ¥è¯†
        domain_knowledge = self.knowledge_base.get_domain_knowledge(
            category="open_source_project"
        )
        
        # 2. æŸ¥æ‰¾ç›¸ä¼¼é¡¹ç›®
        similar_repos = self.knowledge_base.find_similar_repos(repo_key)
        
        # 3. æ„å»ºåˆ†æ Prompt
        prompt = f"""
ä½ æ˜¯ä¸€ä¸ªå¼€æºé¡¹ç›®ç”Ÿæ€åˆ†æä¸“å®¶ã€‚è¯·åŸºäºä»¥ä¸‹æ•°æ®æä¾›ç»¼åˆåˆ†æï¼š

ã€æ—¶åºæ•°æ®ã€‘
{json.dumps(timeseries_data, ensure_ascii=False, indent=2)}

ã€æ–‡æœ¬æ•°æ®æ‘˜è¦ã€‘
{self._summarize_text_data(text_data)}

ã€é¢†åŸŸçŸ¥è¯†ã€‘
{domain_knowledge}

ã€ç›¸ä¼¼é¡¹ç›®å¯¹æ¯”ã€‘
{json.dumps(similar_repos, ensure_ascii=False)}

è¯·æä¾›ï¼š
1. æ•´ä½“è¯„ä¼°ï¼ˆ200å­—ï¼‰
2. å…³é”®æ´å¯Ÿï¼ˆ3-5æ¡ï¼‰
3. æ”¹è¿›å»ºè®®ï¼ˆ3-5æ¡ï¼‰
4. ä¸è¡Œä¸šåŸºå‡†çš„å¯¹æ¯”åˆ†æ
"""
        
        # 4. ç”Ÿæˆåˆ†ææŠ¥å‘Š
        analysis = self.llm_client.generate(prompt)
        
        return self._parse_analysis(analysis)
```

#### 3.2 å¤šæ¨¡æ€å¤„ç†

**åŠŸèƒ½**ï¼š
- ç»“åˆæ—¶åºå›¾è¡¨ï¼ˆè§†è§‰æ¨¡æ€ï¼‰
- æ–‡æœ¬æ•°æ®ï¼ˆè¯­è¨€æ¨¡æ€ï¼‰
- å…ƒæ•°æ®ï¼ˆç»“æ„åŒ–æ•°æ®ï¼‰

**å®ç°æ€è·¯**ï¼š
- ä½¿ç”¨å¤šæ¨¡æ€ LLMï¼ˆå¦‚ GPT-4Vã€Claude 3ï¼‰
- æˆ–åˆ†åˆ«å¤„ç†å„æ¨¡æ€ï¼Œç„¶åèåˆ

**å½“å‰é˜¶æ®µ**ï¼šå…ˆå®ç°æ–‡æœ¬+æ—¶åºçš„èåˆï¼Œè§†è§‰æ¨¡æ€ä½œä¸ºæœªæ¥æ‰©å±•ã€‚

---

## é¡¹ç›®ç»“æ„æ”¹é€ 

### æ–°çš„ç›®å½•ç»“æ„

```
backend/
â”œâ”€â”€ app.py                          # Flask APIå…¥å£ï¼ˆä¿æŒä¸å˜ï¼‰
â”œâ”€â”€ data_service.py                 # æ•°æ®æœåŠ¡ï¼ˆä¿æŒä¸å˜ï¼‰
â”‚
â”œâ”€â”€ Agent/                          # æ™ºèƒ½ä½“æ¨¡å—ï¼ˆæ‰©å±•ï¼‰
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ qa_agent.py                 # Q&Aæ™ºèƒ½ä½“ï¼ˆç°æœ‰ï¼‰
â”‚   â”œâ”€â”€ deepseek_client.py          # DeepSeekå®¢æˆ·ç«¯ï¼ˆç°æœ‰ï¼‰
â”‚   â””â”€â”€ time_series_agent.py        # æ–°å¢ï¼šæ—¶åºåˆ†ææ™ºèƒ½ä½“
â”‚
â”œâ”€â”€ LLM2TSA/                        # æ–°å¢ï¼šLLM2TSAæ ¸å¿ƒæ¨¡å—
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚
â”‚   â”œâ”€â”€ enhancer.py                 # æ¨¡å¼1ï¼šæ•°æ®å¢å¼ºå™¨
â”‚   â”‚   â”œâ”€â”€ TimeSeriesEnhancer
â”‚   â”‚   â”œâ”€â”€ TrendDetector
â”‚   â”‚   â””â”€â”€ SemanticFeatureExtractor
â”‚   â”‚
â”‚   â”œâ”€â”€ predictor.py                # æ¨¡å¼2ï¼šé¢„æµ‹å™¨
â”‚   â”‚   â”œâ”€â”€ LLMTimeSeriesPredictor
â”‚   â”‚   â”œâ”€â”€ PromptBuilder
â”‚   â”‚   â””â”€â”€ ResultParser
â”‚   â”‚
â”‚   â”œâ”€â”€ agent.py                    # æ¨¡å¼3ï¼šæ™ºèƒ½ä½“
â”‚   â”‚   â”œâ”€â”€ TimeSeriesAgent
â”‚   â”‚   â”œâ”€â”€ KnowledgeBase
â”‚   â”‚   â””â”€â”€ MultiModalProcessor
â”‚   â”‚
â”‚   â”œâ”€â”€ llm_client.py              # LLMå®¢æˆ·ç«¯ç»Ÿä¸€æ¥å£
â”‚   â”‚   â”œâ”€â”€ BaseLLMClient
â”‚   â”‚   â”œâ”€â”€ DeepSeekClient
â”‚   â”‚   â””â”€â”€ OpenAIClientï¼ˆå¯é€‰ï¼‰
â”‚   â”‚
â”‚   â””â”€â”€ utils.py                    # å·¥å…·å‡½æ•°
â”‚       â”œâ”€â”€ timeseries_formatter
â”‚       â”œâ”€â”€ prompt_templates
â”‚       â””â”€â”€ result_parser
â”‚
â”œâ”€â”€ DataProcessor/                  # æ•°æ®å¤„ç†å™¨ï¼ˆä¿æŒä¸å˜ï¼‰
â”‚   â”œâ”€â”€ github_text_crawler.py
â”‚   â”œâ”€â”€ data_processor.py
â”‚   â””â”€â”€ ...
â”‚
â””â”€â”€ KnowledgeBase/                  # æ–°å¢ï¼šçŸ¥è¯†åº“æ¨¡å—
    â”œâ”€â”€ __init__.py
    â”œâ”€â”€ domain_knowledge.py         # é¢†åŸŸçŸ¥è¯†
    â”œâ”€â”€ similar_repo_finder.py      # ç›¸ä¼¼é¡¹ç›®æŸ¥æ‰¾
    â””â”€â”€ benchmark_data.py           # è¡Œä¸šåŸºå‡†æ•°æ®
```

---

## æ•°æ®æµè®¾è®¡

### 1. æ•°æ®å¢å¼ºæµç¨‹

```
æ—¶åºæ•°æ® (timeseries_data.json)
    â†“
TimeSeriesEnhancer.enhance_metric()
    â†“
LLMç”Ÿæˆæè¿°å’Œè¶‹åŠ¿åˆ†æ
    â†“
å¢å¼ºåçš„æ•°æ® (timeseries_data_enhanced.json)
    â†“
å‰ç«¯å±•ç¤ºï¼ˆå¸¦è¯­ä¹‰æè¿°ï¼‰
```

### 2. é¢„æµ‹æµç¨‹

```
å†å²æ—¶åºæ•°æ®
    â†“
LLMTimeSeriesPredictor.predict()
    â†“
æ ¼å¼åŒ–æ•°æ® â†’ Promptæ„å»º â†’ LLMè°ƒç”¨
    â†“
è§£æé¢„æµ‹ç»“æœ
    â†“
å‰ç«¯å±•ç¤ºé¢„æµ‹å›¾è¡¨
```

### 3. æ™ºèƒ½ä½“åˆ†ææµç¨‹

```
æ—¶åºæ•°æ® + æ–‡æœ¬æ•°æ® + å…ƒæ•°æ®
    â†“
TimeSeriesAgent.analyze_repository()
    â†“
åŠ è½½é¢†åŸŸçŸ¥è¯† + æŸ¥æ‰¾ç›¸ä¼¼é¡¹ç›®
    â†“
æ„å»ºç»¼åˆåˆ†æPrompt â†’ LLMç”ŸæˆæŠ¥å‘Š
    â†“
å‰ç«¯å±•ç¤ºåˆ†ææŠ¥å‘Š
```

---

## APIæ¥å£è®¾è®¡

### 1. æ•°æ®å¢å¼ºæ¥å£

```python
# GET /api/enhance/<repo_key>/metrics
# è·å–æ‰€æœ‰æŒ‡æ ‡çš„å¢å¼ºä¿¡æ¯

# GET /api/enhance/<repo_key>/metric/<metric_name>
# è·å–å•ä¸ªæŒ‡æ ‡çš„å¢å¼ºä¿¡æ¯

# GET /api/enhance/<repo_key>/summary
# è·å–æ•´ä½“è¶‹åŠ¿æ€»ç»“
```

**å“åº”ç¤ºä¾‹**ï¼š

```json
{
    "metric_name": "OpenRank",
    "description": "OpenRankæŒ‡æ ‡åæ˜ äº†é¡¹ç›®çš„å¼€æºå½±å“åŠ›...",
    "trends": [
        {
            "period": "2020-08 to 2021-02",
            "type": "ä¸Šå‡",
            "description": "é¡¹ç›®å½±å“åŠ›å¿«é€Ÿæå‡ï¼ŒOpenRankä»4.76å¢é•¿è‡³5.81"
        }
    ],
    "key_points": [
        {
            "date": "2020-12",
            "value": 12.65,
            "description": "è¾¾åˆ°å†å²å³°å€¼ï¼Œå¯èƒ½ä¸é‡å¤§ç‰ˆæœ¬å‘å¸ƒç›¸å…³"
        }
    ],
    "semantic_features": {
        "growth_rate": "ä¸­ç­‰",
        "stability": "è¾ƒé«˜",
        "seasonality": "æ— æ˜æ˜¾å­£èŠ‚æ€§"
    }
}
```

### 2. é¢„æµ‹æ¥å£

```python
# POST /api/predict/<repo_key>
# è¯·æ±‚ä½“ï¼š
{
    "metric_name": "OpenRank",
    "forecast_months": 6,
    "include_reasoning": true
}

# å“åº”ï¼š
{
    "forecast": {
        "2025-12": 4.8,
        "2026-01": 5.1,
        "2026-02": 5.3,
        ...
    },
    "confidence": 0.75,
    "reasoning": "åŸºäºå†å²è¶‹åŠ¿åˆ†æï¼ŒOpenRankåœ¨è¿‡å»6ä¸ªæœˆå‘ˆç°ç¨³å®šä¸Šå‡è¶‹åŠ¿..."
}
```

### 3. æ™ºèƒ½ä½“åˆ†ææ¥å£

```python
# POST /api/agent/analyze/<repo_key>
# è¯·æ±‚ä½“ï¼š
{
    "analysis_type": "comprehensive",  # comprehensive / quick / detailed
    "include_comparison": true,
    "include_recommendations": true
}

# å“åº”ï¼š
{
    "overall_assessment": "é¡¹ç›®å¤„äºå¿«é€Ÿå¢é•¿æœŸ...",
    "key_insights": [...],
    "recommendations": [...],
    "comparison": {...}
}
```

---

## å®ç°æ­¥éª¤

### é˜¶æ®µ1ï¼šåŸºç¡€æ¶æ„æ­å»ºï¼ˆ1-2å‘¨ï¼‰

1. **åˆ›å»º LLM2TSA æ¨¡å—ç»“æ„**
   ```bash
   mkdir -p backend/LLM2TSA
   touch backend/LLM2TSA/__init__.py
   ```

2. **å®ç°ç»Ÿä¸€çš„ LLM å®¢æˆ·ç«¯æ¥å£**
   - å°è£… DeepSeek å®¢æˆ·ç«¯
   - æ”¯æŒæœªæ¥æ‰©å±•å…¶ä»– LLMï¼ˆOpenAIã€Claudeç­‰ï¼‰

3. **åˆ›å»ºåŸºç¡€å·¥å…·å‡½æ•°**
   - æ—¶åºæ•°æ®æ ¼å¼åŒ–
   - Prompt æ¨¡æ¿ç®¡ç†
   - ç»“æœè§£æå·¥å…·

### é˜¶æ®µ2ï¼šæ¨¡å¼1å®ç°ï¼ˆ2-3å‘¨ï¼‰

1. **å®ç° TimeSeriesEnhancer**
   - `enhance_metric()`: å•æŒ‡æ ‡å¢å¼º
   - `generate_summary()`: æ•´ä½“æ€»ç»“
   - `detect_trends()`: è¶‹åŠ¿è¯†åˆ«

2. **é›†æˆåˆ°æ•°æ®æœåŠ¡**
   - åœ¨æ•°æ®åŠ è½½æ—¶è‡ªåŠ¨å¢å¼º
   - æä¾› API æ¥å£

3. **å‰ç«¯å±•ç¤ºå¢å¼ºæ•°æ®**
   - åœ¨å›¾è¡¨ä¸Šæ˜¾ç¤ºè¯­ä¹‰æè¿°
   - æ·»åŠ è¶‹åŠ¿è¯´æ˜å¡ç‰‡

### é˜¶æ®µ3ï¼šæ¨¡å¼2å®ç°ï¼ˆ2-3å‘¨ï¼‰

1. **å®ç° LLMTimeSeriesPredictor**
   - `predict()`: é¢„æµ‹ä¸»å‡½æ•°
   - `_format_timeseries()`: æ•°æ®æ ¼å¼åŒ–
   - `_parse_prediction()`: ç»“æœè§£æ

2. **Prompt å·¥ç¨‹ä¼˜åŒ–**
   - è®¾è®¡å¤šç§ Prompt æ¨¡æ¿
   - A/B æµ‹è¯•é€‰æ‹©æœ€ä½³æ¨¡æ¿

3. **å‰ç«¯é¢„æµ‹å±•ç¤º**
   - é¢„æµ‹å›¾è¡¨ç»„ä»¶
   - ç½®ä¿¡åº¦å¯è§†åŒ–

### é˜¶æ®µ4ï¼šæ¨¡å¼3å®ç°ï¼ˆ3-4å‘¨ï¼‰

1. **æ„å»ºçŸ¥è¯†åº“**
   - é¢†åŸŸçŸ¥è¯†æ”¶é›†å’Œæ•´ç†
   - ç›¸ä¼¼é¡¹ç›®åŒ¹é…ç®—æ³•
   - è¡Œä¸šåŸºå‡†æ•°æ®

2. **å®ç° TimeSeriesAgent**
   - `analyze_repository()`: ç»¼åˆåˆ†æ
   - å¤šæ¨¡æ€æ•°æ®èåˆ
   - æŠ¥å‘Šç”Ÿæˆ

3. **å‰ç«¯æ™ºèƒ½åˆ†æé¡µé¢**
   - ç»¼åˆåˆ†ææŠ¥å‘Šå±•ç¤º
   - å¯¹æ¯”åˆ†æå¯è§†åŒ–

### é˜¶æ®µ5ï¼šä¼˜åŒ–ä¸æ‰©å±•ï¼ˆæŒç»­ï¼‰

1. **æ€§èƒ½ä¼˜åŒ–**
   - LLM è°ƒç”¨ç¼“å­˜
   - æ‰¹é‡å¤„ç†ä¼˜åŒ–
   - å¼‚æ­¥å¤„ç†

2. **åŠŸèƒ½æ‰©å±•**
   - å¤šæ¨¡æ€æ”¯æŒï¼ˆå›¾è¡¨è¯†åˆ«ï¼‰
   - æ¨¡å‹å¢å¼ºå±‚ï¼ˆåŒå¡”æ¨¡å‹ï¼‰
   - è°ƒå‚è·¯å¾„å®ç°

---

## æŠ€æœ¯æ ˆä¸ä¾èµ–

### æ–°å¢ä¾èµ–

```txt
# backend/requirements.txt æ–°å¢ï¼š

# LLMå®¢æˆ·ç«¯ï¼ˆå·²æœ‰DeepSeekï¼Œå¯é€‰æ·»åŠ ï¼‰
openai>=1.0.0  # å¦‚éœ€æ”¯æŒOpenAI
anthropic>=0.3.0  # å¦‚éœ€æ”¯æŒClaude

# æ—¶åºåˆ†æå·¥å…·
statsmodels>=0.14.0  # ç”¨äºè¶‹åŠ¿æ£€æµ‹
scipy>=1.11.0  # ç§‘å­¦è®¡ç®—

# æ•°æ®å¤„ç†
numpy>=1.24.0
pandas>=2.0.0

# å‘é‡æ•°æ®åº“ï¼ˆç”¨äºçŸ¥è¯†åº“ï¼Œå¯é€‰ï¼‰
chromadb>=0.4.0  # æˆ–ä½¿ç”¨å…¶ä»–å‘é‡æ•°æ®åº“

# å¼‚æ­¥å¤„ç†
asyncio  # Pythonå†…ç½®
aiohttp>=3.9.0  # å¼‚æ­¥HTTPå®¢æˆ·ç«¯
```

### ç¯å¢ƒå˜é‡é…ç½®

```bash
# .env æ–°å¢ï¼š

# LLMé…ç½®ï¼ˆå·²æœ‰ï¼‰
DEEPSEEK_API_KEY=your_key_here

# å¯é€‰ï¼šå…¶ä»–LLM
OPENAI_API_KEY=your_key_here
ANTHROPIC_API_KEY=your_key_here

# çŸ¥è¯†åº“é…ç½®
KNOWLEDGE_BASE_PATH=./KnowledgeBase/data
VECTOR_DB_PATH=./KnowledgeBase/vector_db

# ç¼“å­˜é…ç½®
ENABLE_LLM_CACHE=true
CACHE_TTL=3600  # ç¼“å­˜è¿‡æœŸæ—¶é—´ï¼ˆç§’ï¼‰
```

---

## å…³é”®è®¾è®¡å†³ç­–

### 1. LLMé€‰æ‹©

**å½“å‰**ï¼šDeepSeekï¼ˆæˆæœ¬ä½ã€ä¸­æ–‡æ”¯æŒå¥½ï¼‰

**æœªæ¥æ‰©å±•**ï¼š
- OpenAI GPT-4ï¼šé¢„æµ‹ç²¾åº¦é«˜ï¼Œä½†æˆæœ¬è¾ƒé«˜
- Claude 3ï¼šé•¿æ–‡æœ¬å¤„ç†èƒ½åŠ›å¼º
- æœ¬åœ°æ¨¡å‹ï¼ˆQwenã€ChatGLMï¼‰ï¼šæ•°æ®éšç§ä¿æŠ¤

### 2. ç¼“å­˜ç­–ç•¥

**LLMè°ƒç”¨ç¼“å­˜**ï¼š
- ç›¸åŒè¾“å…¥ç¼“å­˜ç»“æœ
- TTLï¼š1å°æ—¶ï¼ˆå¯é…ç½®ï¼‰
- å­˜å‚¨ï¼šRedis æˆ–æœ¬åœ°æ–‡ä»¶

### 3. é”™è¯¯å¤„ç†

**LLMè°ƒç”¨å¤±è´¥**ï¼š
- é‡è¯•æœºåˆ¶ï¼ˆæœ€å¤š3æ¬¡ï¼‰
- é™çº§ç­–ç•¥ï¼ˆä½¿ç”¨è§„åˆ™åŒ¹é…ï¼‰
- ç”¨æˆ·å‹å¥½çš„é”™è¯¯æç¤º

### 4. æˆæœ¬æ§åˆ¶

**ç­–ç•¥**ï¼š
- æ‰¹é‡å¤„ç†å‡å°‘è°ƒç”¨æ¬¡æ•°
- ç¼“å­˜æœºåˆ¶é¿å…é‡å¤è°ƒç”¨
- ä½¿ç”¨æˆæœ¬è¾ƒä½çš„æ¨¡å‹ï¼ˆDeepSeekï¼‰
- è®¾ç½®æ¯æ—¥è°ƒç”¨ä¸Šé™

---

## æµ‹è¯•ç­–ç•¥

### 1. å•å…ƒæµ‹è¯•

```python
# tests/test_enhancer.py
def test_enhance_metric():
    enhancer = TimeSeriesEnhancer()
    result = enhancer.enhance_metric("OpenRank", test_data)
    assert "description" in result
    assert "trends" in result

# tests/test_predictor.py
def test_predict():
    predictor = LLMTimeSeriesPredictor()
    result = predictor.predict("OpenRank", historical_data, 6)
    assert len(result["forecast"]) == 6
```

### 2. é›†æˆæµ‹è¯•

- ç«¯åˆ°ç«¯æµ‹è¯•ï¼šæ•°æ®å¢å¼º â†’ API â†’ å‰ç«¯å±•ç¤º
- LLMè°ƒç”¨Mockï¼šé¿å…å®é™…è°ƒç”¨ï¼ŒåŠ å¿«æµ‹è¯•é€Ÿåº¦

### 3. æ€§èƒ½æµ‹è¯•

- LLMå“åº”æ—¶é—´ç›‘æ§
- å¹¶å‘å¤„ç†èƒ½åŠ›æµ‹è¯•
- ç¼“å­˜å‘½ä¸­ç‡ç»Ÿè®¡

---

## æ€»ç»“

æœ¬æ”¹é€ æ–¹æ¡ˆåŸºäº LLM2TSA çš„ä¸‰ç§æ¨¡å¼ï¼Œå°† DataPulse å‡çº§ä¸ºæ™ºèƒ½æ—¶åºåˆ†æå¹³å°ï¼š

1. **æ¨¡å¼1ï¼ˆå¢å¼ºå™¨ï¼‰**ï¼šä¸ºæ—¶åºæ•°æ®æ·»åŠ è¯­ä¹‰ä¿¡æ¯ï¼Œæå‡å¯è§£é‡Šæ€§
2. **æ¨¡å¼2ï¼ˆé¢„æµ‹å™¨ï¼‰**ï¼šä½¿ç”¨ LLM è¿›è¡Œæ—¶åºé¢„æµ‹ï¼Œæ— éœ€è®­ç»ƒä¼ ç»Ÿæ¨¡å‹
3. **æ¨¡å¼3ï¼ˆæ™ºèƒ½ä½“ï¼‰**ï¼šç»“åˆé¢†åŸŸçŸ¥è¯†ï¼Œæä¾›ç»¼åˆåˆ†æèƒ½åŠ›

**å®æ–½å»ºè®®**ï¼š
- åˆ†é˜¶æ®µå®æ–½ï¼Œå…ˆå®ç°æ¨¡å¼1éªŒè¯æ•ˆæœ
- æ³¨é‡ Prompt å·¥ç¨‹ï¼Œè¿™æ˜¯ LLM åº”ç”¨çš„å…³é”®
- å»ºç«‹å®Œå–„çš„æµ‹è¯•å’Œç›‘æ§æœºåˆ¶
- æ§åˆ¶æˆæœ¬ï¼Œåˆç†ä½¿ç”¨ LLM API

**é¢„æœŸæ”¶ç›Š**ï¼š
- æå‡ç”¨æˆ·ä½“éªŒï¼šæ›´ç›´è§‚çš„æ•°æ®ç†è§£
- å¢å¼ºåˆ†æèƒ½åŠ›ï¼šæ™ºèƒ½é¢„æµ‹å’Œæ´å¯Ÿ
- é™ä½æŠ€æœ¯é—¨æ§›ï¼šæ— éœ€è®­ç»ƒå¤æ‚æ¨¡å‹

---

## é™„å½•

### A. Promptæ¨¡æ¿ç¤ºä¾‹

è§ `backend/LLM2TSA/utils/prompt_templates.py`

### B. çŸ¥è¯†åº“ç»“æ„

è§ `backend/KnowledgeBase/README.md`

### C. APIæ–‡æ¡£

è§ `doc/APIæ–‡æ¡£.md`

---

**æ–‡æ¡£ç‰ˆæœ¬**ï¼šv1.0  
**æœ€åæ›´æ–°**ï¼š2025-12-05  
**ä½œè€…**ï¼šDataPulse Team

